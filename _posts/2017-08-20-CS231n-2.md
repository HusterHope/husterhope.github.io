---
title: 【CS231n-2】计算机视觉的核心任务：图像分类
layout: post
excerpt: 
categories: 做笔记
tags:
  - CV
  - CS231n
  - DL
  - KNN
---

本文内容整理自Stanford Convolutional Neural Networks for Visual Recognition (CS231n Spring 2017) Lesson2

------

#### 一、引言

图像分类（Image Classification）问题：给出带有某种物体的数字图像，如何将图像进行恰当的分类，并保证其合理性？

这一问题对于人类而言并不困难，而对于计算机来说却是一项及其复杂的任务。有关这方面的初步阐述可参考TED公开课《[How we’re teaching computers to understand pictures](https://www.ted.com/talks/fei_fei_li_how_we_re_teaching_computers_to_understand_pictures)》（[网易公开课链接](http://open.163.com/movie/2015/3/Q/R/MAKN9A24M_MAKN9QAQR.html)）。

总的来说，这是因为人和计算机之间存在语义差距（Semantic Gap）。

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-1.png)

图1 Semantic Gap

对于一张800*600像素的彩色图片而言，人类只需不到500ms的时间即可分辨图上的内容；而计算机接收到的输入却是800*600*3大小的矩阵（3代表RGB三个颜色通道）。并且，在摄像机位置变动、图片本身内容变动、光照、环境背景等产生变化时，可能导致图像矩阵产生大范围变化。

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-2.png)

图2 环境变化的识别

因此，我们并没有一种显而易见的算法来实现 **接受一个图像矩阵输入->输出该图像的类别 **这样的功能。

于是引入了数据驱动的方法（Data Driven Approach），可以简单分为以下三步：

\1. Collect a dataset of images and labels 2. Use Machine Learning to train a classifier 3. Evaluate the classifier on new images

1. 收集图像及其对应类别的数据集；
2. 使用机器学习的方法来训练分类器；
3. 对新图像应用分类器。

------

#### 二、最简单的分类器：kNN

最简单的分类器：kNN（k Nearest Neighbor），可参考：[kNN算法理论和实战](http://leohope.com/%E5%81%9A%E7%AC%94%E8%AE%B0/2017/02/19/knn/)／[kNN算法模拟示意图](http://vision.stanford.edu/teaching/cs231n-demos/knn/)

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-3.png)

图3 kNN算法模拟效果

很明显，这是一个不需要训练的算法，而每次应用该算法进行分类的时候都需要遍历整个数据集，时间复杂度O(N)。而我们期望的往往是利用训练阶段得到一个不错的分类器，而在使用阶段消耗尽量短的时间得到结果。

引入概念：超参数(Hyperparameters)，这些参数是我们进行设置和调整的，而不是通过机器学习的过程获取的。

为了设置好超参数，往往需要将数据集划分成训练集、验证集和测试集。其中验证集用于测试超参数的设置优劣，在将超参数调整完毕后，再通过运行测试集来获得模型最终的效果。

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-4.png)

图4 数据集的划分

一般来说，kNN算法不用于图像识别。

------

#### 三、线性分类器——神经网络（Neutal Network）的基础

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-5.png)

图5 线性分类器和神经网络

线性分类器是一种参数方法，通常的形式是：

f(W,x) = Wx + b

其中，x代表输入图像转化而成的列矩阵（如32*32像素的彩色图像，则有32*32*3=3072行），W代表参数矩阵，我们期望Wx得到的结果也是列矩阵，且行数即是整个数据集中图片的类别总数，比如10类，则本例中W就应该为10*3072大小的矩阵。b是常矩阵，用以表达与输入集无关的分类常数。

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-6.png)

图6 线性分类器的数学原理

那么，这个神秘的参数矩阵W做了什么事情呢？我们不妨将训练后的W重新还原成对应的10类图像（这个时候将每行参数映射回一幅图像），会得到有趣的结果。

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-7.png)

图7 理解线性分类器

事实上，如果把一幅图像的全部数据想像成二维平面上的一个点，那么线性分类器便是在这个二维平面内，对于不同类型图像画出的分界线。

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-8.png)

图8 线性分类器的作用

既然是线性分类器，自然也有它很难做到的分类，比如：

![img](http://ohn6qfqhe.bkt.clouddn.com/CS231n2-9.png)

图9 线性分类器的难点

如何对其进行优化，并判断应用效果的好坏？这就是下一课讲解的内容了。

------

