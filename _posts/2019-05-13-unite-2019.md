---
title: "Unite Shanghai 2019 参会记录"
layout: post
categories: 做笔记
tags:
  - AR
  - VR
  - MR
  - Hololens
  - ARKit
  - ARCore
  - Re3D
  - Unite2019
---

第二次参加Unity中国区开发者大会，记录一些值得记录的产品、idea、和故事。

<!-- more -->

会议从5月10日晚上开始，到5月12日下午6点结束。第一天晚上主要是官方介绍本届大会的看点和Unity的迭代方向（主题演讲），后两天的主要活动集中在4个技术分会场，每天上午4场，下午6场，每场45分钟的技术报告，公共区域由各个公司展示相关设备或产品。

## Unity 新特性

先说10号晚上的主题演讲。

伴随着刺眼的射灯和高分贝的背景音乐，主题演讲再一次延迟数分钟开始，延迟半小时结束。完整视频和内容简介可以参见Unity官方平台的回顾：[Unite Shanghai 2019 Keynote ：以China Unity践行服务中国的承诺](https://mp.weixin.qq.com/s/cRbo-dUgx5JrGdyKlHqWcA)。市场合作、本土化和产品案例抛外，简单梳理一下Unity今年主推的技术创新点：

* 面向数据技术栈(DOTS,Data-Oriented Technology Stack) -> 实现动态世界海量内容渲染
* 着色器视图(Shader Graph)和轻量级渲染管线(LWRP) -> 可视化创作
* AR Foundation -> 跨平台AR开发

第一点主要是Unity平台自身的内核优化，以[MegaCity](https://unity.com/megacity)这个项目为学习参考，可以作更多深入了解。

第二个主要给技术美术带来更多方便，是2018版本就在主推的Unity产品迭代方向，可见这条线还在延续。

第三个方向，AR Foundation的架构，非常符合Unity的思想——跟跨平台相关的事情都不应该是开发者需要担心的。大致定位是：

> AR Foundation提供了一个独立于平台的脚本API和MonoBehaviour，通过使用[ARCore](https://developers.google.com/ar/)和[ARKit](https://developer.apple.com/arkit/)共有的核心功能，构建同时适用于二个平台的应用程序。

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-1.jpg)

AR Foundation同时支持Shader Graph编辑和LWRP的应用，因此可以构造出一些酷炫的虚拟特效。比如现场演示的透明材质特效：

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-2.jpg)

（全场观众响起第一次Bravo..）

## AR & VR

顺着AR的故事，继续讲讲11号和12号的分享会中，跟AR和VR技术相关的专场。主要旁听了下面这些（按技术专场编号和时间先后排列）：

* Carrie Shiung (@Google) - ARCore为你解锁增强现实的未来
* 杨橙 (@Google) - Google ARCore全新功能及开发技术深度解析
* Ashley Alicea (@Unity) - Unity 增强现实工具：AR Foundation
* 王子彬&栾青 (@Sensetime) - AI 赋能 AR 的开发与应用
* 謝禮安&袁东(@HTC) - 进入 5G + VR 新时代

### ARCore相关

这次大会没有出现ARKit相关的演讲，公共区域也没看到苹果的展台，于是ARCore就成了一家独大，甚至出现了两场报告内容部分重叠，关键数据不一致的插曲（某一场说当下支持ARCore的设备全球突破4亿台，另一场说突破10亿台）。

第一次跑通ARCore的示例程序大概正好在一年前，这期间也没什么使用需求。前一阵重新上手跑一个Unity插件，发觉ARCore已经迭代到了1.9，文档和学习样例都完整了不少。

AR的开发包通常包含三大功能：设备追踪、环境理解和光线估计。

ARCore当前版本重要新feature包括：

* Augmented images

通过预存储图像数据库，在场景中检测2d图像，返回与数据库相匹配（trackable）的信息。注意，预存储的图像最好达到一定质量分数要求（arcoreimg工具测量），避免大量压缩，避免出现大量重复特征。

典型应用是AR地图，尤其适合于室内AR导览。

此外，对于图像相对设备的移动，ARCore会保存移动图像在场景中最后的pose信息，从而不会出现「图像从场景中消失后，增强图像后的模型也连带消失」的情况。这种设置能够解决一些应用上的痛点，比如大模型的浏览。单凭文字描述有些抽象，举个几年前的例子（From某手游的AR场景）：

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-3.jpg)

* Augmented face

之前说ARKit比ARCore强大的地方就在利用结构光做面部建模，而ARCore终于推出了属于自己的算法框架，且不需要深度传感器——利用深度学习直接从前置摄像头捕捉的二维人脸数据实时得到面部三维模型（468个点组成的网格），提供每个点的xyz、uv、法线信息，30fps。该功能可离线使用。

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-4.jpg)

* HDR lighting

估计场景光照信息，能够使场景中的虚拟物体更具真实感。早期ARCore的环境光线估测算法，基本可以归纳为对图像中的亮度取平均。在移动设备算力提升后，相关算法也在逐渐迭代。最新算法则是结合了深度学习模型，综合估计方向、强度、环境光。

这个学习算法的数据集构造值得一提。某Google工程师在手机上安装了一个支架，支撑三个估计不同光照的小球，让每张2d图像内容和对应光照信息都得到建模。装置和图像采集如下：

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-5.jpg)

### AR + AI

商汤科技的专场，讲了不少AR+AI应用案例，以及目前的研究趋势。可供积累idea。

产品和技术演化过程，**在面部交互上从大到小，从场景理解上从小到大。**

* 交互：全脸 -> 眼球 -> 嘴形 -> 眼神（目光方向）

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-6.jpg)

* 场景理解：平面检测 -> 特殊物体识别 -> 全局建模

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-7.jpg)

### 5G + VR

5月10号下午签到后逛展，体验了HTC新推出的VR一体机[Vive Focus](https://www.vive.com/cn/product/vive-focus/)。虽然硬件层面宣称能够达到6DoF，但目前来看还需要在算法层做足够优化，保障用户的使用安全。作为最初一批接触Vive系列设备的用户，6自由度VR应用仍然给我一种并不踏实的感觉。当然，一体机确实比有线的Vive(Pro)用起来更舒适。（图为当前Vive大家庭）

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-8.jpg)

5G+VR这场汇报是HTC公司的专场，一方面是介绍自家产品，另一方面也描述了VR行业部分现状和发展趋势。

首先讲VR/AR行业近年来仍在快速发展，HTC VR相关产品市场占有率依然领跑市场（全球市场中Sony紧随其后，国内市场基本HTC一家独大）。

其次是5G能够给VR带来的影响：

* VR应用云计算
* VR数据云存储
* 跨平台的适配

最后几个发展趋势：

* 时域真实感（Temporal realism），主要是对延迟的控制。
* 视觉真实感（Visual realism），包括更高的显示分辨率，更精细的虚拟模型。
* 空域真实感（Spatial realism），体现在场景内不同物体间深度信息的处理。
* 语义真实感（Semantics realism），作出更自然的交互和感知。

今年HTC工作人员的分享中，透露出这样一种趋势：**虽然目前看来AR和VR差异明显，但未来会逐渐交叉和融合。**两者各自吸收彼此的优点，打造出虚实融合MR的效果。

具体来说，AR应用通常借助普通的智能手机的相机就能体验，像曾经的《[Pokeman GO](https://www.pokemongo.com/en-us/)》，当下热门的《[一起来捉妖](https://zhuoyao.qq.com/main.shtml)》。而随着移动设备性能提升，曾经的瓶颈在逐步被打破，AR的玩法会远远不止这些。当下VR应用，要么是借助PC端外加臃肿的头显设备，要么屈服于VR一体机不那么高的运算和续航能力，距离全面大众化还很远。这一期间，5G和VR共同发展，逐步克服计算能力上的瓶颈。今年Unite大会，无论是官方推动还是各个公司技术分享的内容，对AR的呼声明显提高了很多，斗胆预测AR的风口会发生在VR到来之前。相关科研工作的推动和落地，未来两年的爆款产品还会成为风口。VR的普及大概还要看这波5G的浪潮，以及优质内容的生产。

而之所以说两者可能走向融合，是因为HTC汇报中开始强调Vive Pro头显配备的相机和相关算法了，包括二维的图像分割，三维的场景重建（深度相机）。可见**VR硬件也在尝试构建虚拟和现实的桥梁，而不局限于「对虚拟世界的无限向往」**。从交互上看，类似于MR设备的手势识别将成为发展趋势，从而取代目前不那么自然的手柄。反过来，从AR的角度看，近几年智能设备上掀起的「全面屏」风潮，也是尽可能让显示更加完美：消除手机边框，打破虚拟和真实的墙。

以下三张图片分别是二维、三维和交互方面的案例。

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-9.jpg)

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-10.jpg)

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-11.jpg)

## Unity 故事

技术之外，Unite大会最吸引我的地方，就是听各个行业的技术人员，讲述Unity和自己团队的故事。游戏设计和开发、电影和动画的制作、研究领域的创新、传统和现代的结合…越是跨专业，越能以一种学习的心态去欣赏，所以这部分整理不会太技术向。

比较有印象的场次如下（同样按技术专场编号和时间先后排列）：

* Mike Solovykh (@Baobab) - 《Crow: The Legend》互动叙事：传统动画与VR动画的探索
* 西村和真&白山俊太郎 (@DELiGHTWORKS) - 对城宝具：CRIWARE技术助力《FGO》高效开发⽣动音频
* Ron Martin (@Unity) - 《头号玩家》背后的技术：Unity虚拟拍摄解决方案解析
* 张雨辰 (@故宫博物院) - 技术与⽂文化的融合：Unity引擎与数字故宫的实践结合案例分享
* 柳丛&张霁 (@叠纸游戏) - 《闪耀暖暖》技术分享：2D到3D的进化与创造之路
* 盛斌 (@上海交通大学) - DeepOD：基于深度学习与Unity VR的牙齿正畸智能辅助技术 
* 邬浩 (@DataMesh) - DataMesh Director案例分享：基于Unity打造数字孪⽣叙事工具

### 游戏

作为并不资深的玩家，幸运的发现了三款体验过的游戏。其中为了听ARCore专场，错过了《Overcooked》团队的技术分享，略遗憾。下面就听到的两场简要讲些印象。

* 《[FGO](https://www.fate-go.jp/)》音频团队专场

[CRIWARE](https://www.criware.com/cn/)算是Unity大会中熟悉的面孔，还记得去年结合游戏《[少女前线](http://gf.ppgame.com/web/pc/index.html)》的演讲挤得爆满。

> CRI Middleware是一家为电子游戏行业提供音频和视频解决方案的领先供应商。 

今年则由《FGO》的团队来讲音频开发中的问题。原以为这个大IP会引来不少粉丝围观，但似乎并没有出现像去年那样的场景，可能是因为过于细节，以及边讲边翻译的节奏比较慢吧。

音频中的主要问题包括：优先级、分类、波形、效果、响度、流类型等。

FGO这款产品2015年上线时，音频数量5000左右，2019年2月则突破38000个。CRIWAVE ADX2工具让wav文件的压缩率达到90%以上（1000个语音文件压缩后大约28MB）。

然后是版本管理，某些限定活动结束后的版本回退问题。

接下来归纳了音视频业务流程：检查 -> 制作 -> 整合。

最后讲了一个录音工作的彩蛋：用手在粗糙平面上的摩擦声，模拟了毛笔字的书写声音。这场分享不让拍照，也就点到为止了。

* 《[闪耀暖暖](https://nikki4.papegames.cn/)》团队专场

这一场分享内容分技术和美术两块，颇为良心。就个人体验+台湾服务器玩家讨论来看，游戏本身的玩法创新性一般，更像是《恋与制作人》+《奇迹暖暖》的组合版。但听了这场分享后，团队在不少细节层面做足了功夫，不少细节甚至肉眼无法察觉。下面记录其中的一个点，来自美术研发柳丛先生对服装纹理制作过程的分享。

为了仔细研究不同服装的差异，他先是通过对现有服装进行实地考察，触摸、拍摄、分类，找到影响服装纹理的核心因素——编制方式。

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-12.jpg)

然后对不同编制方式加以提炼，得到了服装的底层程序化纹理。

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-13.jpg)

以这些纹理为服装肌底，在Unity Shader Graph中逐层叠加材质和图案信息，得到最终效果。

然而，这些底层纹理细节在游戏中真的很难观察到。但如果丢失，可能会给整体观感打一些折扣。

有游戏媒体已经整理出了演讲全部内容的报告：[《闪耀暖暖》如何实现顶级美术表现？先看看叠纸怎么做3D建模吧](https://mp.weixin.qq.com/s/TThkLGwVLP2khZWhREVjOA)。全文比较长，如果真的对技术细节感兴趣，可以戳进去看看。

然而吹了这么多，这游戏公测预约了一年，在大陆地区仍然没有拿到版号（摊手

### 影视

* @Baobab团队专场：VR动画的探索

主要用的是Unity的Timeline功能。

为了让VR内容更有代入感，在单纯播片的基础上，加入了一些交互场景。

与其说是动画，核心思想和游戏也很像：使用一些有限的状态机(state machine)来判定触发条件，用一些简单的交互方式（比如挥手）让用户参与到影片中。

制作方面，先用Maya做预渲染动画片段，特效和交互在Unity内实现。

* 《头号玩家》中的虚拟拍摄解决方案

两天的技术分享会上听到的第一场，足够惊艳。

可以简单概括为给导演使用的VR产品。让导演在虚拟环境中漫游，控制相机的位置和旋转，记录下生成的相机轨迹。从而做到真正意义上的「所见即所得」。

几个点：

-> [Magic leap](https://www.magicleap.com/) 能扫描真实世界场景

-> 有些场景拍摄时，可以直接使用巨型LED屏幕来代替传统的绿幕，直接完成虚实结合。

使用案例如下图所示，其中橙色梯子为场景中的滑轨，演讲者手持设备可以视为遥控器：

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-14.jpg)

### 工业

* DataMesh Director案例分享

说到讲故事，真的比较佩服DataMesh的CTO邬浩。去年听他讲MR+广电制播的案例时，就比较欣赏这种叙述风格。今年直接带来了三个结合MR的工业界案例，主要是To B的案例分享。

> C端展现体验，B端解决需求。

所谓的数字孪生，通俗来说就是混合现实的产品说明书。

要说这次大会最期待的硬件设备，当属Microsoft Hololens 2。然而现场工作人员透露，目前Hololens2的相关展示主要集中在美国，本次Unite大会官方没能从美国搞来两台亮相，稍显遗憾。

而这场分享也是两天内唯一听到介绍Hololens2的演讲。从已知消息来看，Hololens2支持识别更多手势，并且做到了识别手部骨架，实现「在现实世界中抓取虚拟物体」这样的操作。

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-15.jpg)

案例和我们比较远，就当听故事+解决实际问题的思路。不过科研工作和业界思路确实有些差别，此处不展开了。

### 其他

* 数字故宫

汇报人非常谦虚的说，这场演讲没什么技术干货。然而这里却存在着不少进行展示的idea，非常能够体现人文精神。最大的感受是，故宫的数字化团队的能力被外界严重低估了。

核心理念：保护 -> 研究 -> 展示

几个案例：

-> AR 宫廷服饰穿搭

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-16.jpg)

-> 沉浸式 数字多宝阁

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-17.jpg)

-> 文物研究

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-18.jpg)

-> 无障碍 「触摸国宝」

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-20.jpg)

* 牙齿正畸智能辅助的可视化

这一场是交大计算机系的盛斌老师主讲，其实跟VR和Unity都没太大关系，算是这两天内所有演讲中最学术的一场。主要介绍了他们团队跟交大附属医院口腔医学团队的合作研究工作。目前这份工作还没有发表，所以很多细节也没有深入了解的途径。

研究动机方面，由于牙齿正畸的需求不断增长，医生的经验往往是有限的、高度个性化的。可视化主要是为了让医患之间更好的沟通，以及将医疗术语与实际三维效果相结合。

![](https://github.com/HusterHope/blogimage/raw/master/unite2019-19.jpg)

整体关键词：可视化、Deep Learning、口腔医学。之后如果paper出来，写学术报告再细挖。

## 趋势

结合上面的整理，大致归纳应用方面如下发展趋势：

云服务的趋势

* 5G+VR
* 云游戏
* AI协助

自然交互的趋势

* 丢掉手柄，加入触感
* 面部细节捕捉和建模
* 6 DoF

虚实融合的趋势

* VR与AR相结合

---

至于Unity平台本身，这几年也在游戏引擎的基础上，延伸出了各行各业的应用。正如它的名字一样，初心未改，向着「有机统一」的趋势逐步迈进，

大红色的文化衫，赫然印着：Unity for all.

最后用一张书签收尾。

![](https://github.com/HusterHope/blogimage/raw/master/20190513.jpg)