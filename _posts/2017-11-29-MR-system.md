---
title: "Reading | 一种用于空间协作的混合现实(MR)远程系统"
layout: post
excerpt: "A Mixed Reality Telepresence System for Collaborative Space Operation"
categories: 读论文
tags:
  - VBR
  - VR
  - MR
  - 3D
  - Re3D
  - Telepresence
---

本文整理自Allen J. Fairchild, Simon P. Campion, Arturo S. García, Robin Wolff, Terrence Fernando, and David J. Roberts等人的文章「A Mixed Reality Telepresence System for Collaborative Space Operation」（IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY, VOL. 27, NO. 4, APRIL 2017），以了解行业最新进展。

---

### 摘要

本论文的系统整合了两个系统：一个远程呈现$_{[注]}$（Telepresence）系统和一个模拟火星探索的应用。本系统将自由视点的视频和沉浸式投影技术相结合，来支持非语言交流（NVC, Nonverbal Communication，包括眼神，人际交往的距离和面部表情等）信息。重要的是，当人们在模拟环境中走动时，所有的这些信息可以被同步解读。

> 注：Telepresence这一单词也译作网真(Google)、临场感(Baidu)等，但感觉这几种翻译方式都没有准确表达出这个词的原意，故本文暂时以“远程呈现”作为其翻译，读者如有更好的译法欢迎指出。

#### 贡献

系统贡献：一个支持NVC的MR系统。

技术贡献：从动态背景中提取人物轮廓的方法；轻量级多视点纹理渲染方法。

实践贡献：在不同沉浸程度的显示系统之间共享空间。

研究工具的贡献：在一个鼓励探索和社交的环境里，支持对传统创作的和基于视频重建的化身进行比较。

#### 关键词

基于视频的三维重建；背景前景分割；计算机支持的协作；混合现实（MR）；太空科学；远程呈现。

### I 简介

本项目用以支持欧盟「CROSS-DRIVE计划」，该计划的目标是促进国与国之间在太空任务、科学和工程领域上的合作。

要实现传输NVC信息的困难在于：在不限制人物移动范围的情况下（比如没有坐在一把椅子上），很难同时传输一个人的全身模型及其面部表情。而NVC具有内在的空间性，必须真实模拟出大范围NVC语境并加以应用。

>设想，一个科学家和一个工程师同时处在火星模拟环境中，空中有一个火星探测器。科学家用手指向探测器应该着陆的位置，而工程师却未持统一意见。而此时探测器正好对着科学家方向，因此执行了科学家的指令。

子挑战：包含运动图像的背景分割；通过墙面显示器实现空间交互；实时面部纹理渲染；支持3D化身的缩放；在不遮挡眼部的情况下共享空间。

###  II 背景

* Mixed Reality(MR)：混合现实通过媒体和显示器，融合真实世界和虚拟世界的信息。

#### 在远程呈现（Telepresence）中创建NVC

* 远程呈现（Telepresence）：一种通过技术营造的的临场感。该术语通常用于描述那些试图在远距离重现面对面会议的系统。

重组NVC可以采用以下方式：

##### 视频

可捕捉大部分NVC信息。但超出镜头范围的有效信息将丢失；无法重现眼神交流（因为摄像头和屏幕中心不在同一位置，用户同一时间内只能观察其中之一）

##### VR

3D沉浸，能捕捉NVC并通过化身(Avatar)重现。但同时捕捉面部细节和全身动作相当困难。

##### 3D重建视频

通过多视频流重建化身，避免用户被各种捕捉设备所约束。但需要平衡视觉、空间和时效性。

#### 现场重建3D化身

分为主动完成和被动完成。

##### 主动完成

基于ToF(Time-of-Flight)设备，例如Kinect：通过计算光的传播时间以得到距离深度图。再通过多处采集的数据重建3D模型。

##### 被动完成

基于图像的重建(Image Based Reconstruction, IBR)：用普通相机从多角度拍摄。

高质量的重建在实时性上存在不足，因此选用从剪影重建模型(Shape-from-Silhouette, SfS)的方法。

|      | 主动完成(Kinect) |  被动完成(SfS)   |
| ---- | :----------: | :----------: |
| 采样规模 |  小（320*240）  | 大（1000*1000） |
| 采样范围 |      小       |      较大      |
| 拼接错误 |      有       |      较少      |
| 背景要求 |      无       |    易分割的背景    |

#### 利用沉浸式显示和现场重建来情景化大范围NVC

利用当下现有的媒体和显示技术来保留大范围NVC是具有挑战的。

沉浸式显示主要分为头戴式设备和大型投影显示设备。

头戴式设备会完全遮挡眼部信息；沉浸式投影通常需要3D眼镜，也会干扰眼部图像。

近期的研究中，采用Kinect摄像机采集用户形体数据，并在屏幕中实现三维重建。我们的研究采用了10台Kinect摄像机从多方位采集数据。

* 选择从具有移动物体或图像的背景中分割前景物体的方法。

初步方法：将多视点视频合并成沉浸式投影。利用回归反射(retro-reflective)材料让用户观察到投影图像，且不会被周围的摄像机捕捉。

缺点：材料不允许从后方投影；投影质量取决于材料质量。

后续方法：从单色背景中分割前景。

缺点：用户不能进行空间上的交互。

解决方案在后文中描述。

### III 可协作的混合现实系统

将现有的远程呈现系统和火星模拟系统整合。

#### 理想化系统全貌

最先进的全方位采集和显示设备，基于多点视频进行实时三维重建并投影。每个用户拥有独立的沉浸式空间，多个用户之间共享同一个虚拟空间。

![](https://github.com/HusterHope/blogimage/raw/master/AMR-1.png)

#### 现有系统

「CROSS-DRIVE」目前只有一台理想化系统中描述的沉浸空间设备，其他均为墙面显示和计算机桌面终端。

并且，目前不支持全空间的投影和图像分割，因此只有一面墙上的显示器可以工作。

现有系统示意图如下：

![](https://github.com/HusterHope/blogimage/raw/master/AMR-2.png)

##### 远程呈现系统

![](https://github.com/HusterHope/blogimage/raw/master/AMR-3.png)

###### 基于视频的三维重建

该部分包括视频获取、背景分割和三维重建。

* 视频获取：通过相机阵列。
* 背景分割：可分为可见光谱分割和红外光谱分割，这两种分割方式的结果在第IV部分描述。
* 三维重建：并行化精确多面体视觉外壳（EPVH, Exact Polyhedral Visual Hulls）的实现。系统需要获取相机的图片平面和现实世界坐标系的关系。

###### 分布式

将三维网格重建和纹理映射的模块分开渲染，用以提高实时性，减轻带宽压力。同时，对需要传输的视频和3D网格采用LZMA算法压缩。

###### 三维模型渲染

解压->纹理映射->渲染

计算模型表面某一点的颜色时，采用如下方法：

![](https://github.com/HusterHope/blogimage/raw/master/AMR-4.png)

即：对不同相机所获得图像进行加权分配获得颜色，并根据观察者的视角，将最近视角的相机图像加以颜色混合。运用这种混合颜色方法可以改善某些位置的图像效果，比如下图右起第二个人物的手部重影问题。

> 这一步骤的第二步个人感觉计算细节有些问题，$e_i = |V||C_i|cos(\beta_i)$的结果会大于1，$b$取$e_m$中某个值时也会出现此情况。

![](https://github.com/HusterHope/blogimage/raw/master/AMR-9.png)

##### 火星模拟系统

可解析巨量数字化地形模型(DTM, Digital Terrain Model)的数据。

渲染器参考地理特征数据创建DTM，并提供地理信息系统中常见的交互式工具。

#### 整合

当用户从三维采集空间内加入火星探测会话时，该用户将由一个三维重建的化身代替传统的计算机图形意象(CGI, Computer Graphics Imagery)化身。系统将重建节点的服务器地址与其他参与者进行通信，并打开与重建节点的连接，以接收3D网格和视频流。服务器在远程客户端连接后立即开始传输。

此外，整合的系统中还增加了一个转换矩阵。首先，将捕捉空间的原点，即三维重建化身的原点与火星模拟器中世界坐标系原点对齐；其次，将在捕捉空间中的单位匹配渲染器空间中的单位。这样，重建的化身在远程虚拟环境中才看起来是真实大小，并且处于对应的位置和方向。使用我们目前的相机配置，在捕捉中心1.5米半径内的任何位置，都可以捕捉和重建人物，使他们的视线和面部表情都很清晰。

### IV 结果

本节主要描述该系统的实际质量。

#### NVC的视觉质量和交流

* 背景分割算法

![](https://github.com/HusterHope/blogimage/raw/master/AMR-5.png)

本系统采用基于高斯混合的实现方法（效果为上右），可更好地避免锯齿、粘贴等问题。

* 面部采集

在相机校准的情况下，得到的面部采集图像如下：

![](https://github.com/HusterHope/blogimage/raw/master/AMR-6.png)

需要指出，相机高度会对重建质量产生影响，比如引起下垂效果，使用户看起来伤心，老化或不适。这一点在用户越接近捕捉空间边界而体现的越明显。

* 支持不同硬件设备

由于不是每个用户都拥有3D捕捉系统或沉浸式显示器，因此本系统支持不同的硬件设备。当然，佩戴头戴式VR设备和3D眼镜会丢失面部细节的捕捉。

![](https://github.com/HusterHope/blogimage/raw/master/AMR-7.png)

#### 背景分割

首先，在确保所有设备均不会发射红外线的情况下，我们选用红外光谱分割的方法（因为几乎只有用户自身会发射红外线，方便从光谱中提取轮廓）。

下图为不同设备进行红外光谱分割的效果，显然，右下图效果最好。

![](https://github.com/HusterHope/blogimage/raw/master/AMR-10.png)

#### 时效性

|    进程     | 用时(ms) |
| :-------: | :----: |
|   网格压缩    | 118.5  |
|   网格解压    |  23.4  |
| 视频解压(10帧) |  16.1  |
| 向GPU传输纹理  | 105.2  |
| 向GPU传输网格  |  27.3  |
|    渲染     |  0.05  |

#### 衔接测试

目前系统衔接图如下

![](https://github.com/HusterHope/blogimage/raw/master/AMR-8.png)

三维化身是从全方位采集设备传送来的。我们在DLR中使用代理服务器将其发送到桌面客户端，而不是直接发送给每个用户，从而减少了所需的带宽。

### V 讨论

非言语行为之间的联系与熟悉和信任相关联，并用于调节交往的过程，例如决定一个对话是否应该开始或是结束。正因如此，在一切圆桌会议上，目前的通信技术一般效率都不高，因为人们的行动受到限制。当人们不能在共享的环境中彼此移动时，将人们的注意力集中在周围的事物上是很难的。

我们的方法在视频和VR的质量之间折衷，即平衡视觉、空间和时间的质量，以支持人际距离、眼神和面部表情及其相互关联。

### VI 结语

本研究的直接影响包括提高分布式团队的凝聚力，降低国际合作的成本。同时，这种技术可以在许多其他领域实施，比如灾害现场的联合应急指挥和控制，远程医疗等。当然，最大的影响可能是为远程呈现的相关研究添砖加瓦。这项技术将会帮助人们在远距离协作领域的研究走的更加开阔。此外，还能从根本上减少人们对旅行的依赖，提高生活质量。

---

