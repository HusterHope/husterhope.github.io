---
title: "Reading | 利用视点熵进行视点选择"
layout: post
excerpt: "Viewpoint Selection using Viewpoint Entropy"
categories: 读论文
tags:
  - CG
  - 3D
---

本文整理自Pere-Pau Va ́zquezz , Miquel Feixasz , Mateu Sbertz , and Wolfgang Heidrich等人的论文《Viewpoint Selection using Viewpoint Entropy》VMV 2001Stuttgart, Germany, November 21–23, 2001 ，文章发表的时间很早，但文中的内容很实用，研究方法也颇为规范，整理借鉴，积累经验。

---

### 摘要

观察一个三维场景时，选择一个好的**视点(Viewpoint)**十分重要（*视点*可以直观理解成观察角度，或摄像机摆放位置），这一点也被应用在一些领域中，如计算几何、视觉伺服(Visual servo)、机器人运动和图形绘制等。此外，在计算机图形学领域，基于图像的渲染(IBR, Image Based Rendering)也依赖于视点选择。

[^视觉伺服 ]: “伺服”—词源于希腊语“奴隶” 。视觉伺服是由Hill和Park于1979年提出的。一般指的是通过光学装置和非接触型传感器自动地接收和处理一个真实物体的图像，通过图像反馈的信息，来让机器系统对机器做进一步控制或相应的自适应调整的行为。

虽然人们对一个视点的好坏没有一致的评价标准，但从直观上而言，一个好的视点应该**包含更多信息**。在这篇论文里，我们使用信息学理论来定义一个新的评价标准：视点熵。同时，我们也将选择一个视点集合来实现场景理解。最后，我们根据视点熵的评价标准设计了一个自动场景漫游的算法。

### I 简介

在计算机图形学领域，要定义术语*好的视点(Good view)*是很困难的。不过，一个包含了更多信息的视点，更可能会被认作一个较好的视点。比如，设想三维空间中存在一个球体和一个立方体，当从不同的视点观察时得到下面两幅图，我们自然会认为视点(b)比(a)更好。

![](http://ohn6qfqhe.bkt.clouddn.com/ViewEn-1.png)

如果场景的几何信息全部已知，那么所有物体的面片信息都是可以被我们加以利用的。下面我们将依次描述以下内容：第2节主要回顾前人的相关工作，并进一步验证*好的视点*的概念；第3节提出我们的方法；第4节探讨如何从一个场景中选出*N个好的视点*；第5节描述自动场景漫游；最后，在第6节总结我们获得的结果。

### II 前人工作

在过去的十年间(1990-2000)，视点选择一直是一个热门研究领域。这一节我们整理部分前人的方法。

#### 计算机图形学

Kamada和Kawai认为，如果沿一个视点上的正交投影使图形面片数损失最小，则该视点是一个*好的视点*，但这个方法在损失相同时无法给出取舍，并且不保证结果中包含的细节最多。

Barral等人改进了Kamada的方法。他们采用透视投影，并同时考虑面片数和投影面积，提出一种加权方案。问题是，加权系数难以确定，且该方法作用于带有孔洞的物体时效果不佳。

Hlavac等人则将选取工作和IBR相结合。总的来说，他们选择一组场景周围的视点，并在保证误差可控的前提下，利用这些视点所获取的图像重建场景，这个视点集合中包含的视点就是*好的视点*。但问题也显而易见：该方法无法评价单个视点的优劣。

#### 其他领域

Bourque和Dudek定义了图像中*有趣点(Interesting Point)*的概念。这些有趣点通常会被人们更多关注到，包含更多有趣点的视点或许是好的视点。

Arbel和Ferrie使用熵的概念作目标识别；Takeuchi和Onishi通过测量图像直方图强度的熵来找出场景中的复杂部分。这两个案例都用到了熵和概率分布的相关计算，但和本文的目标不同。

Roberts和Marshall等人所定义的好的视点是，与物体每个面的法线同时处于最小角度的视点。

#### 什么是好的视点？

我们已经提到了一些定义，但领域内依然没有达成一种共识。可以肯定的是，一个好的视点必须尽可能的帮助我们理解场景。

从前人的工作中，我们找到了两个特别影响视点质量的因素：**投影后的区域**和**可见面片数**。不过，投影区域并不直接包含信息。同时，可见的面片不能太小。例如同一场景有以下两个视点的图像，它们具有不同的投影面积和可见面片数，如何评判哪一个更好呢？

### III 视点熵

我们首先假设：一个视点所包含的**信息**，可以理解为**可见性**。

接下来我们定义**视点熵**，来帮助我们从场景中获取更高质量的视点。

#### 视点熵

香农(Shannon)对**熵**的定义是：离散型随机变量$X$可在集合$\{a_1,a_2,…,a_n\}$中取值，$X$的熵$H(X)$由下式计算得出：

$$H(X) = -\sum_{i=1}^{n}p_ilog\ p_i\qquad\qquad(1)$$

熵反映了随机变量的**不确定性**，信息的单位是*bit*。

> To define viewpoint entropy we use as probability distribution the relative area of the projected faces over the sphere of directions centered in the viewpoint.

*上面原文里的这段话反复读了半天实在不知道该怎么理解。大意是，将场景放在一个球体区域的中心，然后在球面上移动以寻找视点，并为此定义随机变量和视点熵。*

视点熵定义如下：
$$H(X) = -\sum_{i=0}^{N_f} \frac{A_i}{A_t}log\frac{A_i}{A_t}\qquad\qquad(2)$$

其中，$N_f$是场景中面片的数量，$A_i$是第$i$个面片在该视点下的投影面积。$A_0$代表背景的投影面积，$A_t$是总投影面积。值得说明的是，$A_i/A_t$的值与面片法线和视线的夹角余弦值成正比，和视点到面片的距离成反比，这就同时保证了视线角度和被观察物体的大小。

该方法的缺点是：必须使用一个额外的背景面片来接收投影。否则，视点距离场景的远近对熵的计算不构成影响，这和我们的选择目的不一致。

#### 实现

```
算法1：选择最大视点熵
创建一系列环绕场景的视点
定义变量maxI、viewpoint,并均赋初值0
对所有的视点执行如下循环：
	计算视点熵，将值赋给变量aux
	如果aux > maxI，则
		maxI = aux
		视点(viewpoint)调整为当前点
输出maxI和视点信息
```

#### 结果

在相机围绕一个立方体转动视点时，得到熵和投影面积如下：

![](http://ohn6qfqhe.bkt.clouddn.com/ViewEn-2.png)

由图可见，基本符合预期值。

对更加复杂的情况，例如下图中的圆环和桌子，拥有最大视点熵的视点如图所示，

![](http://ohn6qfqhe.bkt.clouddn.com/ViewEn-3.png)

但是很多时候，仅依靠一个视点无法满足应用需求，比如基于图像的三维重建和场景理解，因此，我们需要更多视点和图像。

### IV 为理解场景而选择多个好的视点

到目前为止，我们已经明白了如何选择单个好视点。在这一节，我们将找出最适合理解场景的多个视点，并尽量控制视点的数量。对此，我们有如下限制条件：

* 这些视点必须包含丰富的信息；
* 这些视点必须覆盖所有可见面片。

一个简单粗暴的做法就是按照第三节的方法，先计算每个视点的熵，再将它们降序排列，选出前N个视点。然而，这种方法不能保证所有面片都被覆盖。

因此，我们使用位图(bitmap)来存储每个面片是否被覆盖的标记。如算法2所示：

```
算法2：计算视点集合
创建一系列环绕场景的视点
对所有视点执行如下循环：
	计算视点熵并存储
	存储一张标记每个面片覆盖情况的位图
将上述视点按照熵减顺序排列
选择第一个视点（最大熵）
创建一个位图，以记录每个面片的覆盖情况
初始化变量i为0，完成状态为未完成
当i小于总视点数量，且完成状态为未完成时：
	如果第i个视点中，未覆盖的面片数量大于一个阈值：
		选择该视点
		在位图中重新记录面片的覆盖情况
		在覆盖的面片达到一定比例后，将完成状态标记为完成
	i自增1
```

选择桌子的最佳视点集合如下图所示：

![](http://ohn6qfqhe.bkt.clouddn.com/ViewEn-5.png)

### V 自动场景漫游

在第4节中我们找到了一个用于展示场景的最小视点集合。然而，面对一组从不同视点获取的图片，用户可能会产生迷惑（不容易想象这些图片分别来自场景哪些位置）。这可以采用场景漫游的方式，让不同视点间的图片自然过渡。

首先，从视点集合中任意选取一个视点，然后选择下图所示的3个不同漫游方向中的一个方向作为下一步。

![](http://ohn6qfqhe.bkt.clouddn.com/ViewEn-4.png)

选择的方法是：用处在这3个方向上的视点的熵与同它们对应的第4节描述的位图标记之差相乘。

[^注]: 上面这句话读起来比较拗口。说得明白一点：我们要计算两个量的乘积，其中一个量是某一方向上的视点熵，另一个量是一个位图标记的差值（回顾第4节中的位图标记），这个差值的计算是用新视点的标记值减当前视点的标记值，也就等价于在切换视点后，新覆盖的面片数量。

之后，选择乘积最大者。倘若3个方向的视点的计算结果有部分相同，则选择距出发视点最远的方向。

漫游这一步有很多其他方法可以选用，不再展开。

### VI 结论和未来工作

这篇论文定义了一种评价视点质量的新标准：**视点熵**，这个概念基于信息论。

进一步，通过视点熵可以得出便于理解一个场景的视点集合。

我们的算法基于面片外部的可见性，这意味着只能对物体外部进行观察。未来，我们将会研究观察模型内部的视点选择问题。此外，我们还将对视点熵计算过程进行优化，并加入艺术相关方面的讨论，使视点质量的评判标准更加科学和客观。