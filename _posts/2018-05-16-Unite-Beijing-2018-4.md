---
title: "Unite Beijing 2018 (4) Unity+VAMR"
layout: post
tags:
  - Unite2018
  - AR
  - VR
  - MR
  - ARKit
  - iOS
  - ARCore
  - Android
  - Kinect
  - Hololens
categories: 做笔记
---

本文为Unite2018会议记录第四篇，也是最后一篇。主要整理Unity+VR/AR/MR相关的数据/应用/平台和硬件设备。其他几篇相关文章可以在[这个链接](https://leohope.com/tag/#/Unite2018)里找到。

本部分内容包括：ARKit，ARCore，小米+OculusVR，以及两场与Microsoft Hololens相关的MR报告。

<!-- more -->

## ARKit面部追踪

由Unity XR技术专家Dan Miller主讲。

硬件环境：Macbook+iPhone X

软件环境：ARKit+Xcode

关键技术：Visual inertial odometry（VIO），上述硬件+软件已集成。

流程：通过iPhone X的前置摄像头检测面部变化细节，反馈给Unity-ARKit，后者完成渲染。

效果：实时面部网格生成，可替换网格材质球。

![](https://github.com/HusterHope/blogimage/raw/master/unite4-1.jpg)

其他：

* 局部坐标系

  ARKit能够在Unity中生成头部的局部坐标系，实现一些简单应用（比如戴帽子）。不过默认状态下虚拟物体的渲染会覆盖在摄像机图层中的最上层，需要手动调整虚拟物体位置。

![](https://github.com/HusterHope/blogimage/raw/master/unite4-2.jpg)

![](https://github.com/HusterHope/blogimage/raw/master/unite4-3.jpg)

* GameObject Recorder

  实时记录面部表情的参数，后期可以应用于生成虚拟人物的表情动画。

![](https://github.com/HusterHope/blogimage/raw/master/unite4-4.jpg)

相比上一篇文章中提到的传统手调动画，ARKit结合iPhone X的应用可以明显加速虚拟角色的面部表情制作，从精度和实时性上来说已经可以投入应用了。

或许存在的问题是，面部表情数据如何同肢体动作数据进行融合？

## ARCore开发

听完了ARKit的应用现状，紧接着就由Google技术经理Wim Meeussen介绍ARCore。

开场，Wim指出一个现状：近10年间，智能手机的性能提升已经十分显著了，但交互方式上从未有革命性的创新。

比如使用手机查看地图的时候，面对的还是虚拟的界面，并没有与真实世界直接互动。

> AR就是将手机和真实世界联系在一起的工具。
>
> 为了在手机上实现「增强现实」，手机需要先知道什么是「现实」。
>
> 运用AR，从更多角度观察内容，让世界变为你的工作平台。

打完鸡血后开始将技术细节。

### AR Phones

将普通手机变成支持AR手机，需要加入以下核心技术：

* 动作追踪
* 场景理解（最简单的包括平面检测）
* 光线估计

Google的早期产品：2014年 Tango phone，采用IR镜头+鱼眼镜头+双摄，但是没有获得市场认可。

2018年，Google正式推出ARCore，在不同安卓设备上提供技术支持。

### 应用介绍

- AR视频分享
- 购物（特别是家具）
- 测量工具（场景中的距离估算）
- 游戏（解谜游戏）

### 给开发者的Tips

（这部分终于算是干货了）

Wim Meeussen列出以下实用建议：

- AR是一个比较新的概念，需要引导用户如何使用（比如移动或旋转手机）；
- 需要及时反馈AR识别的信息（比如检测出的平面），让用户对应用的功能有初步认知；
- 注意引导用户避障；
- 开发前应规划好应用的使用场景或范围（桌面级/室内场景级等）；
- 尝试通过移动手机来展示应用细节，而不仅仅是动画；
- 避免用户在使用时向后移动（防止被身后的障碍物绊倒）
- 提升真实感：在虚拟场景中加入投影效果（让用户感觉虚拟物体和真实世界产生了互动）
- 在场景中创建新物体时，提示位置
- 不要使用大角度的旋转交互（因为真实世界不会跟着旋转）
- 发布产品时需注明：AR Required/AR optional（必须项/可选项）

### 开发者工具

- Poly资源商店
- Blocks and Tilt Brush
- 使用空间锚（Anchor）定位物体
- 使用安卓模拟器（在Android Studio内）进行测试
- GAPID tool
- 官方站：https://developers.google.cn/ar/

## 小米VR+Oculus

作为一位米粉，自然要去听听小米相关的动态。

### 一体机性能优化相关问题

本专场主要讲的是小米VR一体机（而不是头套+手机版本的VR Play），因此在优化方面需要更注重沉浸感和用户体验。

* 固定注视点渲染（FFR）

传统意义上的VR显示是全屏无差别的渲染，而人眼在获取环境信息时是存在「视觉中心」的。

![](https://github.com/HusterHope/blogimage/raw/master/unite4-5.jpg)

因此对中心区域和边缘区域采用相同渲染质量十分浪费。团队经过调研后，提出了FFR优化方案。

![](https://github.com/HusterHope/blogimage/raw/master/unite4-6.jpg)

该方案最大性能提升可达25%，而用户的主观感受不会受到太大影响。

* 性能管理与动态频率

智能手机为了维持续航和防止过热，通常会在运行时降频，从而帧速率下降。不过手机用户对帧率下降的主观感受并不明显。

![](https://github.com/HusterHope/blogimage/raw/master/unite4-7.jpg)

（我很好奇为啥小米的PPT上用的是华为进行测试，是怕米粉看了手机降频不买吗hhh）

> VR的世界就是用户看到的另一个真实世界，没有谁的真实世界会掉帧吧？（笑）
>
> 所以，VR应用不能掉帧。

因此，小米VR一体机做了区别于手机的独立硬件和系统。

![](https://github.com/HusterHope/blogimage/raw/master/unite4-8.jpg)

然后就是一些针对开发者的功能：

* 可以手动设置CPU/GPU性能基准；

  系统实现动态频率，但不会低于开发者设定的性能基准（因此建议设置CPU2，GPU2）

* 降频时系统内会发送post（设备过热，需要降频掉帧blabla）；

* 在散热功能的支持下，可开启CPU/GPU level4（手机最多开到level3）

* 在评估模式中建议关闭系统动态频率

* 60/72hz模式

### 一体机SDK

这部分内容主要描述了一些社交相关的优化。

首先：

> **VR最忌讳等待**。

这一点比较容易理解，因为手机/PC端应用，等待时不会影响用户的正常生活（嗑瓜子/喝茶/翻书之类），但VR应用一旦进入等待，用户在佩戴头显的情况下无法完成其他事情，很快就会失去耐心。

而VR内部的社交属性也很欠缺，一方面是用户群体较小，另一方面不容易交互（无法打字输入消息）。为此小米和Oculus合作开发的VR SDK针对多人游戏开发者和产品，主要加入以下功能：

* 小米VR Home（桌面级菜单）
* 平台组队功能，一起进入第三方应用
* 平台级好友列表
* 平台级语音交流（如担心隐私问题可关闭）
* 小米账号一键登录
* ...

### 小米VR平台数据

最后一部分是数据相关的报告，有些数据带着一些趣味性，同时也反映出了一些值得思考的点。

* 用户数量方面：增长势头依然强劲

![](https://github.com/HusterHope/blogimage/raw/master/unite4-9.jpg)

![](https://github.com/HusterHope/blogimage/raw/master/unite4-10.jpg)

* 用户偏好方面：注重视觉刺激体验

![](https://github.com/HusterHope/blogimage/raw/master/unite4-11.jpg)

	（此处全场死宅一起笑）

![](https://github.com/HusterHope/blogimage/raw/master/unite4-12.jpg)

> 另外一个好玩的现象，最受欢迎的应用里包括了「过山车」，但VR体验的初衷是不应该让用户眩晕。据此小米团队随机调查了若干用户，后者表示：因为真实世界的过山车就是要晕，因此使用VR晕了的效果是一样的。（笑）

* 付费情况：用户更关心质量而非价格

![](https://github.com/HusterHope/blogimage/raw/master/unite4-13.jpg)

本次由小米VR/AR产品总监马杰思带来的技术专场，严谨中不失幽默，结构合理，层次鲜明，对VR用户群体的数据和分析报告也比较详尽。全程听下来酣畅淋漓。

愿你们在对VR探索的道路上永不止步，早日做出满足「让每个人都能体会科技的乐趣」这一条件产品。

## MR+多行业应用场景

（这场内容的实际主题和预告主题稍有偏差）

Taqtile Corp公司的亚太市场总监元泓毅，为我们讲解了些当下不同领域的工作中面临的问题，以及如何结合MR应用来解决这些问题。

（个人体会是整体偏虚，故事讲的较多，技术细节较少，就当了解行业前沿应用吧）

### 行业痛点：昂贵和复杂的产品设计流程

MR相关应用可以：

* 节约设计时间和材料成本

![](https://github.com/HusterHope/blogimage/raw/master/unite4-14.jpg)

* 提升团队协作能力

![](https://github.com/HusterHope/blogimage/raw/master/unite4-15.jpg)

* 和客户高效沟通

![](https://github.com/HusterHope/blogimage/raw/master/unite4-16.jpg)

### 理解3D数据并与数字化信息交互

主要列举了如下应用场景：

* 教育行业的应用



* 医疗教学

  免去了重复使用活体标本进行操作，转为操作模型和虚拟场景。

  （个人对可行性方面存疑）

  ![](https://github.com/HusterHope/blogimage/raw/master/unite4-17.jpg)

* 远程协助：应急事件处理/昂贵设备维修

  比如电梯抢修，大型军事设备的维修等。

### 工作效率及安全生产

MR设备可以解放双手，当工人操作过程中需要获取信息时，通常难以查阅相关手册，而MR设备的手势交互能够满足这一需求。

提高生产效率的Video Notes：（维修工师傅操作一遍并结合实物留下教学语音和视频，供小工操作时分步学习）

![](https://github.com/HusterHope/blogimage/raw/master/unite4-18.jpg)

其他应用包括避免生产意外（比如某工人准备开电闸时，结合IoT应用在头显中弹出提示“某处有其他工人在维修电缆，开闸会blabla”）、跨平台远程合作等。

从Hololens的实际体验效果来说，上面大部分应用应该只是「可行」，而非「解决」，毕竟考虑到续航、定位精度和人机交互的识别方面，仍需较大改进。

## MR+现代化办公

这一讲由微软大中华区创新技术合作事业部的用户体验顾问刘昕羽带来，相比标题内容，本专场更像是Microsoft Hololens的产品细节介绍。

（听到最后比较累，拍的多记得少）

### 混合现实五大场景

* 远程协同
* 线下训练
* 空间规划
* 原型设计
* 设备监控

### 3D环境下人和信息的交互

* Display Lock：锁定在显示区域中的某处（就像过去安卓机下方的虚拟按键），通常用户最反感这类方法。
* Body Lock：随着用户的前进和后退而移动，始终与设备保持相对位置固定。
* World Lock：在世界坐标系下放空间锚

以及不同设备所支持的空间自由度列表：

![](https://github.com/HusterHope/blogimage/raw/master/unite4-19.jpg)

### 新一代Kinect产品预告

Project Kinect for Azure

![](https://github.com/HusterHope/blogimage/raw/master/unite4-20.jpg)

* 1024*1024 激光雷达深度相机
* 4K rgb摄像头
* 立体声麦克风阵列

下一代Hololens硬件（预计2018年年底发布）会附带Kinect深度相机。

### MR开发框架介绍

* Unity
* Microsoft MR ToolKit
* Azure Cognitive Services（支持无DL知识背景的开发人员调用API）
* Azure Machine Learning（更底层算法的实现）

作为市面上to B产品中最完善的一款，Hololens需要的革新和优化仍然很多，但这并不妨碍它实现若干简单的应用场景了。

---

### 后记

在实验室导师的支持下，这算是我第一次参加大规模学术+工业的交流分享会。个人经过本科的专业积累，对于大会上的Unity + VAMR/动画/游戏/影视等相关应用均有一定了解和实际体验，但接触都不够深。虽然能够听懂，但缺乏深入学习的过程，除了最相关的三维重建应用外，也没有准备可以同演讲者交流的问题。

如宣传所说，本场活动确实算是Unity开发者的盛筵，汇聚了国内外不少精英演讲者，有一丝不苟写博客的程序员，有边演讲边玩到自嗨的讲师，有演讲时紧张又拘谨的日本动画师，也有能够频繁引发掌声的大作作者。

更重要的是，经过这样的分享会，可能每个在自己领域钻研了很久的人，能够碰上一群志同道合的小伙伴，然后发觉自己并不孤独。

就像小米VR技术专场里马总提到的，为什么我们要做VR？

> 因为我们有着对虚拟世界的无限向往！

**触碰未来，渴望未来，创造未来。**

我想，Unity的万千开发者们，也会因为有着共同的目标，而不断在自己的领域中奋进吧。